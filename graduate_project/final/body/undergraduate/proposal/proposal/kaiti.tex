\clearpage
\chapter{开题报告}
\section{问题提出的背景}

\subsection{背景介绍}
计算流体动力学(CFD)是一个应用非常广泛的领域，较为基础、传统的是对于宏观尺度上的连续流体的模拟，比如说飞机、车辆、船舶的空气动力学或水动力学。又如冷暖空气的流动，预测洋流的变化等。
这些宏观尺度的计算流体力学多出现在工业领域中，有着较为成熟的发展。但是流体仍然是非常复杂的物理系统，它的行为受纳维-斯托克斯方程(Navier Stokes Function, i.e NS Function)控制。

然而由于NS方程高度非线性、多维度、非恒定流动以及复杂的边界条件共同导致了通常情况下很难找到方程的解析解。因此，经典的方法通常转向数值方法、渐进近似方法等技术来解决这些方程。
例如基于网格的有限体积法，有限元方法等，这是 CFD 中广泛使用的数值方法，但这些方法通常通过将计算域进行网格离散化，最终将连续的微分方程转化为离散的线性方程组的形式，这是一个计算成本高昂的过程。
更准确和更先进的 CFD 仿真的主要瓶颈之一是运行这些模型所需的时间。而在大型超级计算基础设施上进行一次模拟需要几天到几周的时间并不少见。

同时随着问题的复杂程度升高，计算资源指数增长，计算速度精度要求不断提高，传统的数值计算方法遇到了一定的挑战，如维度灾难，难以结合实验数据，反问题的挑战等。
近年来，深度学习在计算机视觉和自然语言处理方面的成功应用，促使人们探索人工智能在科学计算领域的应用，特别是在计算流体动力学(CFD)领域，促使人们使用深度学习方法来逼近 PDE 解决方案，并有望解决相关问题。



\subsection{研究的意义和目的}
虽然基于全连接物理信息的神经网络已经得到充分发展，但是对于一些含有参数的PDE，例如未知的初边值条件，未知的几何边界，却少有研究，大多数深度学习模型无法捕获这些方程的全部复杂性，而这些问题对于pde求解来说也至关重要，他们严重影响模拟和计算的效率。
因此卷积网络引起了科研人员的兴趣，因为卷积能够极大减少参数数量，加强了点与点之间的联系。在近些年来也出现了一些基于CNN的pde代理模型.
例如Zichao Long利用CNN中的卷积核代替有限差分方法\cite{pmlr-v80-long18a}；
Nils Wandel使用 U-Net 求解Marker and Cell (MAC) grid上的不可压缩NS方程\cite{Wandel2021Learning}，但这些方法并不专注于精确建模物理过程，相反它们的主要目标是生成逼真的动画。

但利用CNN作为代理模型也有其弊端，因为卷积需要结构化数据，即规范化网格上所有点的值，而针对不规则区域边界问题，我们通常会对区域进行三角化操作从而得到非结构化数据。
且现实中更多重要的数据集都是用图的形式存储的，例如社交网络信息，知识图谱，蛋白质网络等。这些图网络的形式并不像图像是排列整齐的矩阵形式，而是非结构化的信息。
这时图神经网络(GNN)便显得更为重要，最早在21年的一篇工作中研究了基于图神经网络用稀疏非结构化数据挖掘未知PDE机理\cite{learnpdefrom_gnn}。

然而在查找文献的过程中发现对于动态NS方程在不规则区域的模拟只有较少的工作，仅有的研究主要是针对稳态PDE在不规则区域的表现，例如利用Galerkin方法求解稳态的NS方程(time-independent)\cite{GAO2022114502}。
还有一种将利用坐标变换将不规则区域变成规则区域处理\cite{gao_phygeonet:_2020}，但是这种方法我认为并没有真正让模型学习到不规则形状参数。
当然也有将深度学习和有限元方法结合的尝试\cite{https://doi.org/10.1002/pamm.202200306}\cite{pmlr-v119-de-avila-belbute-peres20a}，但大多数都是利用FEM提供的数据，GNN作为代理模型的应用，并没有结合FEM本身的优势。
在20年的一篇工作中提出了FEA-Net\cite{YAO2020112892}方法，考虑将有限元方法和深度神经网络结合起来，但是该方法虽然利用了有限元的思想，但是却只能限制在规则区域。

因此本课题中希望在已有的静态NS图神经网络代理模型进行改进，结合间断有限元方法的优势，能够以更快的速度，更好的精度实现不可压NS方程在不规则区域上的动态模拟。


\section{可行性分析}
目前有让模型学习不规则区域的工作。目前主要有以下几种方法：

1.将区域信息以掩模的形式传入网络，将位置信息作为先验知识，例如以独热编码的形式传入。

2.将不规则区域进行三角化(网格化)操作，后用图神经网络处理。

在这里我认为第一种方法虽然将区域信息传入模型，但是并没有让方程知识和区域信息结合起来,。
而图神经网络受到有限元方法的启发，由于偏微分方程残差的变分形式 (弱形式) ，其中 Neumann 边界条件可以自然地包含在控制方程的弱形式中，
微分算子的阶可以通过部分积分有效地降低，从而大大降低了学习的复杂性。
因此我认为图神经网络在处理不规则区域PDE上有独特的优势。

同时目前也已经有利用图神经网络处理稳态PDE在规则区域上的工作，而对于时空区域上微分方程的模拟我们主要有两种方法：

1.利用Method Of Line将时间域进行离散化。

2.利用自回归方法进行时间步长的迭代。


因此基于 GNN 的学习稳态PDE的方法可以自然的扩展到求解时空偏微分方程。

同时我们考虑间断Galerkin方法(DG)，它结合了有限元方法和有限体积方法中的数值通量，所以它可以更好的将物理信息引入模型学习中去。
因此我们相信DG能够很好的和图神经网络结合，理论上可以建立更精确更快速的数值模拟器。



\section{主要内容}
课题主要围绕以下几个关键词进行：图神经网络(GNN)，间断Galerkin方法，有限体积法(FVM)，时间依赖偏微分方程(time-dependent pde)，不规则区域；

具体的问题可以写作：在不规则区域上，以图神经网络作为代理模型求解二维不可压缩Navier-Stokes方程，如圆柱绕流模拟。I.e.

$$\left\{\begin{aligned} 
    &u_t+u\cdot \nabla u=\frac{1}{\rho}(-\nabla p+\mu \Delta u + f)\\
    &\nabla \cdot u=0\ \text{in}\ \Omega\times [0,T]
\end{aligned}\right.$$
其中$\Omega$为不规则区域，且给出区域上稀疏点的非结构化数据。

主要尝试以下几个方法：
\subsection{图神经网络}
图神经网络是在图对象上运行的深度学习框架，是一种数据结构，通过节点和边自然的表征一组对象及其关系。

广义上来讲，GNN 利用节点和边的结构和特征来实现以下三个任务之一:\\
node classification; link prediction; graph classification;

GNN 的关键思想在于：学习如何通过图中所有节点的边，将信息从当前节点传播到整个图中。
一般的 GNN 框架包含三个步骤来更新节点：
\begin{itemize}
    \item Message computation: 类似与给节点编码，将节点的信息转换成一条“消息”。转换方法有很多种，常见的有将节点信息传入MLP中编码。
    \item Aggregation:信息聚合，将相邻节点的信息进行聚合，合适的聚合方法有求和，平均值和最大值等
    \item Updating:给定来自相邻节点的聚合消息，使用处理器函数更新每个节点的嵌入。
\end{itemize}
它直接对典型 CFD 模拟任务中使用的非均匀网格进行操作，而不是直接在大多数先前工作使用的规则网格上运行，因此有比常用的卷积操作要好很多。

\subsection{间断Galerkin方法\cite{20130601}}

间断 Galerkin (DG) 方法属于有限元方法，它结合了有限元法 (具有弱形式、有限维解和试验函数空间) 和有限体积法 (具有数值通量、非线性限制器) 的优点, 
可以应用于任何形式的网格，允许不同的网格单元采用不同种类逼近函数空间，具有局部守恒性质。
和传统有限元方法的主要区别在于在DG方法中有限元函数空间由分片多项式函数构成，允许在单元边界不连续。

主要有以下优点：
\begin{itemize}
    \item 适用于复杂几何体： 间断Galerkin方法在处理复杂的几何体时表现良好，因为它可以自然地适应非结构化网格。
    \item 高阶准确性： 与传统的有限元方法相比，间断Galerkin方法通常具有更高的数值精度，尤其是在处理高阶PDE时。
    \item 处理激波和间断： 由于其间断性质，这种方法对于处理包含激波和间断的问题非常有效，例如对于守恒律方程组的求解。
    \item 稳定性： 间断Galerkin方法在一些流体动力学和固体力学问题中表现出良好的数值稳定性，特别是在处理激波和间断时。
    
\end{itemize}

\subsection{DG-GCN 架构}
将会利用Dealii开源C++软件包或COMSOL等工业软件作为数据提供，以pytorch为框架编写实验代码，以图卷积神经网络为模型。

由于GCN的形式可以推导为$$y=\sigma (Ug_{\theta}(\Lambda)U^Tx)$$记给定的图结构（Graph）为$\mathscr{G}$，L是其对应的Laplace矩阵，对L进行矩阵分解，$U$是由L的特征向量构建的矩阵， 
$\Lambda$是特征值构成的对角矩阵，$g_{\theta}(\Lambda)$是卷积核，$x$是输入特征，$\sigma$是激活函数。

对于卷积核而言，已有利用$e^{-\frac{ik\pi x}{L}}$作为基函数，即以傅里叶变换为基础进行设计；Chebyshev多项式函数空间为基础设计卷积核。
在有限元方法中同样定义了例如连续分段多项式基函数空间
$$\mathcal{V}_{h}^{p}=\left\{v_h \in\mathcal{H}^{1}(\Omega):v_h|_{K} \in \mathcal{P}_{k}(K), \forall K \in \mathcal{E}_{h}\right\}$$
因此理论上同样可以定义类似的卷积核进行优化。同时对于内罚间断Galerkin方法，可以将加罚项加入到损失项中。还有局部间断Galerkin方法等，具体方法选择还有待学习和探讨。


\section{研究计划进度安排及预期目标}
\subsection{进度安排}
2 月 26 日-3月1日：开学前阅读相关论文，完成相关领域研究现状的探索和文献综述。完成开题答辩。

3 月 2 日–3 月 21 日：能够使用现有的PhyGeoNet以及PIGGN基本的求解器，复现相关论文。学习间断Galerkin方法(Discontinuous Galerkin)和有限体积方法。
复现基于图神经网络利用Galerkin方法解决静态PDE的方法。利用DealII或工业软件如SU2计算出基础圆柱绕流实验数据。

完成DG和GNN两种方法对动态(time-dependent)NS方程在不规则区域上耦合的理论分析部分和结构设计，考虑将数值通量的概念加入模型学习过程。

3 月 22 日–3 月 28 日：完成中期报告，开始准备撰写论文，编写耦合部分程序代码.

3 月 29 日–4 月 29 日：完成求解器代码并进行数值对比实验, 撰写论文初稿, 修改后提交终稿.

5 月 26 日–5 月 31 日：毕业论文答辩

\subsection{预期目标}
在不规则边界条件下，利用图神经网络作为代理模型，结合经典的数值算法(间断Galerkin方法)的优势，完成对NS方程模拟的工作。
期望在NS方程反问题以及正向模拟问题上超越经典算法，例如利用更少的数据和时间等，完成对这些问题的数值实验基准分析；
具体实现代码并对算例进行计算，对网络结构设计进行理论分析，期望增强模型可解释性。

\newpage
% \bibliographystyle{plain}
% \bibliography{body/reference}

\begingroup
    \linespreadsingle{}
    \printbibliography[title={参考文献}]
\endgroup