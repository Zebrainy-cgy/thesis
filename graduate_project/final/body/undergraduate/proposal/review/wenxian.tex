\cleardoublepage
\chapter{文献综述}
\section{背景介绍}
\subsection{前言}

偏微分方程(Partial Differential Equation)非常普遍，在科学、工程、经济和金融领域有着广泛的应用。同时在很多实际工程或产业问题中，问题常常被形式化为偏微分方程的形式。
广泛研究的 PDE 包括物理学中的泊松方程（Poisson’s equation）、纳维-斯托克斯方程（Navier-Stokes equation）、麦克斯韦方程（Maxwell’s equation）、薛定谔方程（Schrödinger equation）及工程应用领域的哈密顿-雅可比-贝尔曼方程（Hamilton-JacobiBellman equation）等。

因此，微分方程描述的物理现象广泛存在于自然科学、民生、经济和工业等领域中，其求解方法研究具有重大的理论和实际工程价值。然而如何精准的模拟并预测这些场的变化，如流场，电磁场甚至是多物理场，是现在比较棘手的问题。
因为对于偏微分方程而言，仅有少部分方程能够由分析的方法得到其精确的解析结果，但是对于绝大多数的偏微分方程而言，由于其一些高度非线性项，其解析解几乎不能显式表达出来。
为此我们发展了PDE经典的数值解法，例如有限差分方法(FDM)，有限体积方法(FVM)，有限元方法(FEM)等。

但是随着对精度，模拟速度要求的提高，传统计算方法也显现出一些弊端。而随着深度学习中自动微分技术的进步，深度学习工具开始为解决这些问题注入新的活力。
同时该交叉方向逐渐形成一个新兴的领域“AI for Science”，旨在通过AI加速数学、物理、化学等基础学科的研究。NeurIPS、ICML等知名AI会议也都会定期举行AI for Science相关的研讨会。

\subsection{对流扩散方程}
对流扩散方程(Convection Diffusion Equation)是一类基本的偏微分方程，是扩散方程和对流（平流）方程的组合，描述了粒子、能量或其他物理量由于扩散和对流两个过程在物理系统内部转移的物理现象,在众多领域有着广泛的应用。
方程通常可以写作
$$\mathscr{L}u=u_t-\nabla\cdot (A\cdot \nabla u)+b\cdot \nabla u + cu=f$$
其中$\nabla\cdot (A\cdot \nabla u)$为扩散项，$b\cdot \nabla u$为对流项。特殊的，稳态对流扩散方程有$-\nabla\cdot (A\cdot \nabla u)+b\cdot \nabla u + cu=f$。

\subsection{经典数值方法}
经典数值方法如FDM，FVM，FEM等，他们通常离散化时间域$[0,T]$，用网格或三角形网络剖分空间区域$\Omega$并在网格上建立简单基函数，最终将连续的微分方程转化为离散的线性方程组的形式。
例如对于常微分方程(ODEs)而言，如Runge-Kutta方法。对于规则区域的微分方程而言，有限差分方法是非常有力的工具。
对于不规则网格而言，FVM和FEM提供了有力的算法和理论支持。虽然这些方法经过几十甚至上百年的发展，其适定性理论已经比较的完善，各种优质(稳定，精确，唯一性)的算法也得到了长足的发展，但我们仍需要指出一些传统方法的缺陷。

1.经典求解算法遭遇维度灾难(Curse of Dimensionality)。即随着求解问题维度的增加，如求解Hamilton–Jacobi–Bellman Equation，数据点的存储以及求解速度指数级增加，可用数据变得异常稀疏，这点从系数(刚度)矩阵上就能看出。
因此利用传统的基于网格的方法求解高维PDE几乎不具备可行性。

2.难以结合实验数据，处理方程未知的情况。经典的数值算法理论上需要完整的方程表达式，包括初边值条件，而在实际的工业生产中往往不会有完整的解析表达式而往往以离散的数据的形式给出。这些数据很可能是稀疏的，残缺的，有噪声的。

3.难以实现反问题(Inverse Problems)求解与设计。反问题用传统的方法非常困难。

\subsection{深度学习方法}
随着机器学习算法以及计算机资源的迅速发展，可用数据的爆炸性增长，深度神经网络(Deep Neural Network)已经在各个方面取得了突破性的成就，如计算机视觉(CV)，自然语言处理(NLP)，强化学习(RL)等。
借助这些算法的强大能力，深度学习在很多现实领域取得了丰富的成果，如数学，工程，药学，材料科学，地球科学等等。
深度学习方法相较于传统计算有如下一些优势：

1.处理大规模(高维)数据。他们能够从大量的数据中挖掘信息，学习到复杂的模式和关联。这在复杂系统学习中显得有为重要。
同时，深度学习方法能够通过随机采样的方式，将PDE问题转化为机器学习问题，避免了网格计算。
因此，在处理高维微分方程时，基于深度学习的微分方程求解方法，比传统方法更具有优势。

2.非线性建模能力。神经网络能够更灵活的捕捉非线性关系。

3.泛化能力强，在复杂的混合问题上表现良好。尤其是一些物理量不能能够准确的已知，并且数据具有噪声的情况。

4.借助自动梯度算法，避免离散化带来的误差累积，能够有效的利用解析解的梯度信息来提高训练效率。



% \subsection{1.4 机理数据结合的方法}
% 由上面可以看出，对于偏微分方程问题建模，通常会用传统的机理驱动的模式，通常为经典的数值计算的方法，还有一种是纯数据驱动建模的方法，通常利用深度神经网络进行学习。然而若是纯机理驱动的方式，计算成本高，速度慢；
% 纯数据驱动的方式又需要大量优质数据，同时泛化能力差，看上去有些天真，因为存在大量的先验知识目前尚未在现代机器学习实践中得到利用。因此将数据和机理相结合的方法于前些年被提出，这能够将两者的优势结合起来，在拥有精度的同时提高计算效率。

\section{国内外研究现状}
\subsection{研究方向及进展}
\subsubsection{数据驱动(Data Driven)}
纯数据驱动的方法其实在十年前就有出现，例如，Rudy在2017年提出利用数据驱动稀疏回归方法来挖掘数据中隐藏的PDE\cite{data-driven_discovery_of_pde}。

但这种方法有一些显然的缺点：依旧遭受离散化带来截断误差的影响；泛化能力差；因此Raissi在2018年提出Deep hidden physics models\cite{10.5555/3291125.3291150}改进了这项工作，利用深度神经网络作为代理模型，大大缩减了模拟的时间，提高了泛化能力。

同时又有一批工作希望寻求未知微分方程或其算子的函数近似结构表示，通过学习相关数据找出背后蕴藏的微分方程模型，进而预测系统动力学特性。
其设计思想是期望采用神经网络表示各种显示和隐式算子，学习函数到泛函的映射能力，而不是传统意义上用基函数的线性组合去逼近，进而实现在输入空间上任意取一点都能够返回相应的函数值。

代表的工作有Lu Lu在2020年的一篇工作介绍了DeepONet\cite{lu2021learning}，能够端到端的学习算子。
Zongyi Li在ICLR2021上提出了傅里叶神经算子(Fourier Neural Operator, FNO)\cite{FNO}，借助傅里叶变换实现了无网格(mesh-free)的特点。这项工作在实际应用中已经有落地的成功案例，效果显著。


\subsubsection{数据与机理结合(Physics informed)}
利用人工神经网络求解PDE早在上个实际90年代就有相关的工作，但那时候主要是将神经网络辅助传统数值求解算法\cite{NEURAL-NETWORK-BASED-APPROXIMATIONS1994}。
将数据和机理相结合的想法正式提出是由Maziar Raissi在2017年首先提出的PINNs(Physics-informed Neural Networks)\cite{RAISSI2019686}的概念。其想法主要是将PDE加入到损失函数中，也就是说用将物理先验信息以损失函数的形式加入到网络当中。
即$Loss=L_{MSE}+L_{PDEs},\ L_{PDEs}=|f|^2=\left|u_t-\mathscr{N}(u, u_x, u_{xx},\cdots)\right|^2$，其中的$\mathscr{N}$为偏微分算子，这种约束条件通常成为软约束(Soft Constrain)。
这项工作主要包括以下几点：
\begin{itemize}
    \item 模拟固定时空区域内方程的数值解，预测未来步长解。
    \item 机理挖掘，即原始方程(参数)部分未知，从而预测出完整的方程(参数)，可以算是简单的反问题。
\end{itemize}
这项工作于2019发表在JCP上，正式拉开数据与机理融合的的时代。
他的缺陷也比较明显：

\begin{itemize}
    \item 对于不同的初边值条件需要重新训练，这意味着对于不同的问题实例需要重新构建和训练网络，这可能会导致较长的计算时间和工作量
    \item 不规则区域可能会影响收敛性，忽略内部的物理行为。
\end{itemize}

值得注意的是在Raissi的工作中，PDEs通常以残差项的形式直接加入到损失函数当中。
因此在随后的几年中，很多工作围绕如何提高模型学习性能，将PDEs作为物理先验信息更好的加入到损失项中展开了讨论：

如Zang在2020年提出将弱解形式加入(Weak Adervaserial Network)\cite{ZANG_WAN}，这对于具有奇点而经典解不存在的问题有独特的优势，同时在解决高维PDE上显现出很大的潜力。
Weinan E针对波动类方程提出以能量积分最小化的形式(Deep Ritz Method)\cite{DRM}进行约束，并将边界上的约束和作为惩罚项加入到损失函数中。
还有一些工作如域分解，网络收敛性研究等。



% \paragraph{WAN}由弱解的定义可以发现对于PDE。

% \paragraph{DRM}...

同时，很多针对处理特殊的问题的PINN的变种开始涌现出来，例如针对解决不规则边界的问题，高维PDE问题，多尺度问题等。


\subsection{存在问题}
\subsubsection{物理先验信息(Physical prior)}
物理先验的信息通常会以PDE的形式给出，同时还会有一些对称性，周期性等硬约束(Hard Constrain)，这通常会直接嵌入到到网络结构当中。
但将PDE仅仅加入到损失函数中似乎远远不够，更多的物理先验知识的嵌入意味着模型更加的智能准确，因此如何更好的将物理先验知识更好的嵌入到模型中是比较大的挑战。

同时在实际的应用当中，数据的获取是十分昂贵且困难的，因此得到的数据可能是稀疏的，残缺的，有噪音的。
因此对于稀疏数据而言，如何通过比较好的机理和数据融合方式使得模型能发挥最好的作用也是目前存在的问题之一。

\subsubsection{高维与不规则区域}
高维和不规则区域一直是经典数值算法的灾区，因为由于计算维度的增加，刚度矩阵开始变得稀疏，存储量指数级增加。
神经网络在高维PDE中展现出潜力，但仍然存在较大的提升空间。尤其不规则区域的问题，似乎是一个非常棘手的问题，目前主要有以下几种方法：
1.将区域信息以掩模的形式传入网络，但效果较差，因为区域信息和PDE信息割裂开。2.利用图神经网络进行网格划分，但是速度慢，因为要根据数据三角化分割等种种原因。


\subsection{研究展望}
在深度学习和PDE相结合的领域未来的研究方向大概可以分为两个方面：

\begin{itemize}
    \item 针对具体的不同问题方法本身的改进，例如针对方程多尺度现象，不规则边界如何处理等。
    \item 在不同的应用场景下实际的应用，例如多尺度耦合问题，多物理场问题等。
\end{itemize}

下面分别介绍：

\subsubsection{多尺度问题(Multiscale Problem)}
计算精度是神经网络作为代理模型一直以来需要关注的问题，
而多尺度问题所关注的便是：

1.如何能够更加精确地同时捕捉到宏观的状态和微观的纹理细节，例如处理问题中存在的奇点，边界层，振荡现象等。
因为虽然物理信息神经网络(PINN)在将物理模型与有间隙和噪声的观测数据集成方面表现出了非凡的前景，但是在要逼近的目标函数表现出高频或多尺度特征的情况下，它们仍然举步维艰。

2.如何建模多尺度耦合的过程。由于一些过程在不同的尺度下本构方程不同，微观过程为宏观过程提供支撑，二者以某种方式耦合在一起。
以地球系统为例，其动力学特性受到物理、化学和生物等过程相互作用影响，这些过程发生在跨越多个数量级的时空尺度，如何将不同尺度的方程耦合在一起是一项具有挑战性的工作。


\subsubsection{多物理场(Multi-physics problem)}
目前多数利用深度学习方法来解PDE的方法都集中在一次解决单个PDE，或者是一类PDE，然而在实际应用的一些场景中往往是由多个物理场叠加而成。
因此在模拟时候给定的不是单个PDE，而是多个PDEs耦合在一起是值的考虑的问题。

例如，考虑一个导体内部的电流密度分布会导致热量的产生，这个热量会影响导体内部的温度分布，进而影响电阻率，从而影响电流密度分布。因此，电磁场和热传导是耦合在一起的，需要同时考虑它们的影响。

另一个例子是磁流体力学(Magnetohydrodynamics)，即磁场和流场的耦合，十分的复杂。这在等离子体物理、地球物理学以及一些工程应用中都有重要的应用。

\subsubsection{与传统数值方法结合}
可以看到目前利用神经网络的方法，和经典的数值算法割裂有点大。然而对于深度学习算法而言，他天然的和经典算法相融。
例如，卷积神经网络中的卷积核可以换为有限差分的刚度系数；图神经网络中的三角分割天然的可以和有限元方法相契合。
而深度学习算法借助自动梯度算法避免了差分的阶段误差，因此如何更好的将两者相辅相成是目前存在的挑战之一。

\newpage

% \bibliographystyle{plain}
% \bibliography{body/reference}

\begingroup
    \linespreadsingle{}
    \printbibliography[title={参考文献}]
\endgroup
